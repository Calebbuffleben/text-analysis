# Roadmap de Melhorias - Sistema de An√°lise Sem√¢ntica para Vendas

**Vers√£o**: 1.0  
**Data**: 2025-01-XX  
**Autor**: Arquitetura de Software / ML Engineering

---

## 1Ô∏è‚É£ Vis√£o Geral do Planejamento

### Objetivo do Plano

Evoluir o sistema de an√°lise sem√¢ntica para reuni√µes de vendas, aumentando robustez, precis√£o e qualidade dos feedbacks gerados, mantendo simplicidade arquitetural e performance adequada.

**Meta Principal**: Gerar feedbacks mais confi√°veis e acion√°veis para vendedores, como:
- "Agora √© o momento de falar sobre pre√ßo"
- "Cliente demonstrando obje√ß√£o - requer abordagem diferente"
- "Cliente pronto para avan√ßar - acelerar fechamento"

### Problemas Atuais que Motivam as Melhorias

**Limita√ß√µes Observadas**:

1. **Contexto Curto**: Classifica√ß√£o baseada apenas no chunk atual, sem hist√≥rico
   - N√£o detecta transi√ß√µes de est√°gio (ex: value_exploration ‚Üí price_interest)
   - N√£o identifica padr√µes ao longo da conversa
   - Pode gerar feedbacks contradit√≥rios em sequ√™ncia

2. **Decis√µes Pontuais**: Cada chunk √© analisado isoladamente
   - Ru√≠do de frases isoladas pode gerar falsos positivos
   - Falta agrega√ß√£o temporal para reduzir instabilidade
   - N√£o considera tend√™ncia sem√¢ntica

3. **Confian√ßa Limitada**: Threshold fixo (0.3) pode ser muito permissivo
   - Textos amb√≠guos podem ser classificados incorretamente
   - Falta m√©trica de ambiguidade sem√¢ntica
   - N√£o diferencia entre alta confian√ßa e baixa confian√ßa

4. **Sinais Sem√¢nticos Limitados**: Apenas categoria + confian√ßa
   - N√£o indica intensidade do sinal
   - N√£o indica dire√ß√£o da conversa (avan√ßando/estagnada/regredindo)
   - N√£o fornece flags sem√¢nticas espec√≠ficas para heur√≠sticas

5. **Falta de Observabilidade**: Dificuldade em entender por que um feedback foi gerado
   - Logs n√£o explicam decis√µes sem√¢nticas
   - M√©tricas de qualidade n√£o s√£o coletadas
   - Valida√ß√£o manual √© trabalhosa

### Princ√≠pios de Design

**Simplicidade**: Manter arquitetura simples e explic√°vel
- Evitar over-engineering
- Preferir solu√ß√µes incrementais
- Manter separa√ß√£o clara de responsabilidades

**Performance**: Lat√™ncia aceit√°vel para tempo quase real
- Primeira an√°lise: < 1s (aceit√°vel)
- An√°lises subsequentes: < 100ms (ideal)
- Cache agressivo quando poss√≠vel

**Modularidade**: Componentes desacoplados e test√°veis
- Python retorna sinais sem√¢nticos estruturados
- Backend decide feedbacks baseado em heur√≠sticas
- F√°cil adicionar novos sinais sem quebrar existentes

**Baixo Custo**: Operar eficientemente sem GPU dedicada
- CPU-first com possibilidade futura de GPU
- Modelos leves quando poss√≠vel
- Cache inteligente para reduzir rec√°lculos

---

## 2Ô∏è‚É£ Diagn√≥stico da Arquitetura Atual

### Pontos Fortes da Implementa√ß√£o Atual

‚úÖ **Base S√≥lida**:
- SBERT multil√≠ngue bem escolhido (paraphrase-multilingual-MiniLM-L12-v2)
- Cache de embeddings dos exemplos funciona bem
- Lazy loading implementado corretamente
- Tratamento de erros gracioso (n√£o bloqueia outras an√°lises)

‚úÖ **Separa√ß√£o de Responsabilidades**:
- Python foca em an√°lise sem√¢ntica
- Backend foca em heur√≠sticas de neg√≥cio
- Interfaces bem definidas

‚úÖ **Performance Adequada**:
- Primeira chamada: ~400-500ms (aceit√°vel)
- Chamadas subsequentes: ~5ms (excelente)
- Mem√≥ria: ~30KB adicional (neglig√≠vel)

‚úÖ **Cobertura de Categorias**:
- 8 categorias bem definidas
- 80 exemplos de refer√™ncia (10 por categoria)
- Cobertura adequada de varia√ß√µes lingu√≠sticas

### Limita√ß√µes Observadas

**1. An√°lise Sem√¢ntica Isolada**

**Problema**: Cada chunk √© analisado independentemente, sem contexto hist√≥rico.

**Impacto**:
- N√£o detecta progress√£o: `value_exploration` ‚Üí `price_interest` ‚Üí `decision_signal`
- N√£o identifica regress√£o: `decision_signal` ‚Üí `objection_soft` ‚Üí `objection_hard`
- Pode gerar feedbacks contradit√≥rios em sequ√™ncia

**Exemplo**:
```
Chunk 1: "Como isso funciona?" ‚Üí value_exploration
Chunk 2: "Quanto custa?" ‚Üí price_interest
Chunk 3: "Preciso pensar" ‚Üí stalling
```
Sistema atual: Tr√™s classifica√ß√µes isoladas  
Sistema ideal: Detecta progress√£o ‚Üí regress√£o

**2. Falta de Agrega√ß√£o Temporal**

**Problema**: Ru√≠do de frases isoladas pode gerar falsos positivos.

**Impacto**:
- Frase amb√≠gua pode ser classificada incorretamente
- Feedback prematuro pode ser gerado
- Instabilidade em classifica√ß√µes consecutivas

**Exemplo**:
```
Chunk 1: "N√£o sei" ‚Üí objection_soft (falso positivo)
Chunk 2: "Mas me interessa" ‚Üí value_exploration
Chunk 3: "Quanto custa?" ‚Üí price_interest
```
Sistema atual: Gera feedback de obje√ß√£o no chunk 1  
Sistema ideal: Agrega contexto e ignora ru√≠do

**3. Sinais Sem√¢nticos Limitados**

**Problema**: Apenas categoria + confian√ßa n√£o fornece informa√ß√£o suficiente.

**Impacto**:
- Backend n√£o sabe intensidade do sinal
- N√£o sabe dire√ß√£o da conversa
- N√£o tem flags espec√≠ficas para heur√≠sticas

**Exemplo Atual**:
```json
{
  "sales_category": "price_interest",
  "sales_category_confidence": 0.85
}
```

**Exemplo Ideal**:
```json
{
  "sales_category": "price_interest",
  "sales_category_confidence": 0.85,
  "intensity": 0.92,
  "ambiguity": 0.15,
  "trend": "advancing",
  "flags": {
    "price_window_open": true,
    "strong_signal": true
  }
}
```

**4. Falta de M√©tricas de Qualidade**

**Problema**: N√£o h√° visibilidade sobre qualidade das classifica√ß√µes.

**Impacto**:
- Dificuldade em ajustar thresholds
- N√£o h√° feedback loop para melhorar exemplos
- Valida√ß√£o manual trabalhosa

### Gargalos T√©cnicos Identificados

**CPU**:
- Modelo SBERT roda em CPU (aceit√°vel, mas GPU seria melhor)
- Primeira classifica√ß√£o √© custosa (~400ms)
- Batch processing n√£o implementado

**Lat√™ncia**:
- Primeira an√°lise: ~400-500ms (aceit√°vel)
- An√°lises subsequentes: ~5ms (excelente)
- **Gargalo**: Se precisar comparar com hist√≥rico, lat√™ncia aumenta

**Confian√ßa**:
- Threshold fixo (0.3) pode ser muito permissivo
- N√£o diferencia entre alta e baixa confian√ßa
- Falta m√©trica de ambiguidade

**Escalabilidade**:
- Cache funciona bem para exemplos
- Mas n√£o h√° cache de compara√ß√µes hist√≥ricas
- Se implementar contexto, precisa otimizar

---

## 3Ô∏è‚É£ Melhorias Sem√¢nticas (SBERT & NLP)

### 3.1 Evolu√ß√£o do Modelo SBERT

**Situa√ß√£o Atual**: `paraphrase-multilingual-MiniLM-L12-v2`
- Dimens√£o: 384
- Multil√≠ngue: ‚úÖ
- Leve: ‚úÖ
- Performance: ‚úÖ

**Op√ß√µes de Evolu√ß√£o**:

**Op√ß√£o A: Manter Modelo Atual (Recomendado para Curto Prazo)**
- ‚úÖ J√° funciona bem
- ‚úÖ Leve e r√°pido
- ‚úÖ Multil√≠ngue
- ‚úÖ N√£o requer mudan√ßas

**Op√ß√£o B: Modelo Maior (M√©dio Prazo)**
- `paraphrase-multilingual-mpnet-base-v2` (768 dims)
- Maior precis√£o, mas mais lento
- Avaliar trade-off precis√£o vs lat√™ncia

**Op√ß√£o C: Fine-tuning (Longo Prazo)**
- Treinar em dados reais de reuni√µes de vendas
- Melhor precis√£o para dom√≠nio espec√≠fico
- Requer dataset anotado

**Decis√£o T√©cnica**: Manter modelo atual por enquanto. Avaliar fine-tuning ap√≥s coletar dados reais.

### 3.2 Expans√£o e Curadoria dos Exemplos

**Situa√ß√£o Atual**: 10 exemplos por categoria (80 total)

**Melhorias Propostas**:

**Curto Prazo**:
- Expandir para 15-20 exemplos por categoria
- Adicionar varia√ß√µes regionais (Brasil vs Portugal)
- Incluir g√≠rias e express√µes informais

**M√©dio Prazo**:
- Curadoria baseada em dados reais
- Remover exemplos que geram falsos positivos
- Adicionar exemplos de casos dif√≠ceis

**Estrutura Proposta**:
```python
SALES_CATEGORY_EXAMPLES = {
    'price_interest': {
        'core': [...],  # Exemplos principais (10)
        'variations': [...],  # Varia√ß√µes lingu√≠sticas (5)
        'edge_cases': [...]  # Casos dif√≠ceis (5)
    },
    ...
}
```

**M√©tricas de Qualidade**:
- Taxa de acerto por exemplo
- Exemplos que geram mais falsos positivos
- Cobertura de varia√ß√µes lingu√≠sticas

### 3.3 Classifica√ß√£o Multi-Label

**Problema Atual**: Apenas uma categoria por texto

**Proposta**: Permitir m√∫ltiplas categorias quando apropriado

**Exemplo**:
```
Texto: "Quanto custa e como funciona?"
Categorias: ['price_interest', 'information_gathering']
Scores: {'price_interest': 0.75, 'information_gathering': 0.68}
```

**Implementa√ß√£o**:
```python
def classify_sales_category_multi(
    self,
    text: str,
    min_confidence: float = 0.3,
    max_categories: int = 2
) -> Tuple[List[Tuple[str, float]], float, Dict[str, float]]:
    """
    Retorna m√∫ltiplas categorias quando scores s√£o pr√≥ximos.
    
    Returns:
        Lista de (categoria, score) ordenada por score
        Confian√ßa geral
        Scores de todas as categorias
    """
```

**Crit√©rio para Multi-Label**:
- Se segunda melhor categoria tem score > 0.7 √ó melhor score
- E ambas acima de min_confidence
- Retornar ambas como relevantes

**Uso no Backend**:
```typescript
if (sales_categories.length > 1) {
  // Cliente est√° em m√∫ltiplos est√°gios simultaneamente
  // Ex: price_interest + information_gathering
}
```

### 3.4 Score de Ambiguidade Sem√¢ntica

**Problema**: Textos amb√≠guos podem ser classificados incorretamente

**Solu√ß√£o**: Calcular m√©trica de ambiguidade

**Algoritmo**:
```python
def calculate_ambiguity(self, scores: Dict[str, float]) -> float:
    """
    Calcula ambiguidade baseada na distribui√ß√£o dos scores.
    
    Alta ambiguidade: scores muito pr√≥ximos entre categorias
    Baixa ambiguidade: uma categoria claramente dominante
    
    Returns:
        float: 0.0 (claro) a 1.0 (muito amb√≠guo)
    """
    if not scores:
        return 1.0
    
    sorted_scores = sorted(scores.values(), reverse=True)
    
    if len(sorted_scores) < 2:
        return 0.0
    
    # Entropia normalizada dos scores
    # Alta entropia = alta ambiguidade
    import numpy as np
    scores_array = np.array(sorted_scores)
    scores_normalized = scores_array / scores_array.sum()
    entropy = -np.sum(scores_normalized * np.log(scores_normalized + 1e-10))
    max_entropy = np.log(len(scores))
    
    return entropy / max_entropy if max_entropy > 0 else 0.0
```

**Uso**:
- Se ambiguidade > 0.7: N√£o gerar feedback (muito incerto)
- Se ambiguidade < 0.3: Alta confian√ßa, pode gerar feedback
- Logar ambiguidade para an√°lise

### 3.5 Detec√ß√£o de Transi√ß√£o de Est√°gio

**Problema**: N√£o detecta mudan√ßas de categoria ao longo do tempo

**Solu√ß√£o**: Comparar categoria atual com hist√≥rico

**Implementa√ß√£o**:
```python
def detect_category_transition(
    self,
    current_category: str,
    current_score: float,
    history: List[Tuple[str, float, int]]  # (categoria, score, timestamp)
) -> Optional[Dict[str, Any]]:
    """
    Detecta transi√ß√µes significativas de categoria.
    
    Returns:
        {
            'transition_type': 'advancing' | 'regressing' | 'lateral',
            'from_category': str,
            'to_category': str,
            'confidence': float,
            'time_delta_ms': int
        } ou None
    """
```

**Transi√ß√µes Importantes**:
- `value_exploration` ‚Üí `price_interest`: Cliente progredindo
- `price_interest` ‚Üí `decision_signal`: Pronto para fechar
- `decision_signal` ‚Üí `objection_soft`: Regress√£o preocupante
- `objection_soft` ‚Üí `objection_hard`: Piorando

**Uso no Backend**:
```typescript
if (transition?.transition_type === 'advancing' && 
    transition.to_category === 'price_interest') {
  // Gerar feedback: "Cliente progrediu para interesse em pre√ßo"
}
```

---

## 4Ô∏è‚É£ An√°lise de Contexto Conversacional

### 4.1 Janelas de Contexto

**Problema**: An√°lise isolada de chunks n√£o captura contexto

**Solu√ß√£o**: Manter hist√≥rico e analisar em janelas

**Implementa√ß√£o no Python**:

```python
class ConversationContext:
    """
    Mant√©m contexto sem√¢ntico da conversa.
    """
    def __init__(self, window_size: int = 10, window_duration_ms: int = 60000):
        self.window_size = window_size  # √öltimos N chunks
        self.window_duration_ms = window_duration_ms  # √öltimos N segundos
        self.history: List[Dict[str, Any]] = []
    
    def add_chunk(self, chunk: Dict[str, Any]):
        """Adiciona chunk ao hist√≥rico"""
        self.history.append({
            'text': chunk['text'],
            'sales_category': chunk.get('sales_category'),
            'sales_category_confidence': chunk.get('sales_category_confidence'),
            'timestamp': chunk['timestamp'],
            'embedding': chunk.get('embedding')
        })
        # Manter apenas janela relevante
        self._prune_history()
    
    def get_window(self, now: int) -> List[Dict[str, Any]]:
        """Retorna chunks na janela temporal"""
        cutoff = now - self.window_duration_ms
        return [
            chunk for chunk in self.history
            if chunk['timestamp'] >= cutoff
        ][-self.window_size:]
```

**Uso no TextAnalysisService**:
```python
# Manter contexto por participante/reuni√£o
self.conversation_contexts: Dict[str, ConversationContext] = {}

def analyze(self, chunk: TranscriptionChunk):
    # ... an√°lise atual ...
    
    # Adicionar ao contexto
    key = f"{chunk.meetingId}:{chunk.participantId}"
    if key not in self.conversation_contexts:
        self.conversation_contexts[key] = ConversationContext()
    
    context = self.conversation_contexts[key]
    context.add_chunk({
        'text': chunk.text,
        'sales_category': sales_category,
        'sales_category_confidence': sales_category_confidence,
        'timestamp': chunk.timestamp,
        'embedding': embedding
    })
    
    # An√°lise com contexto
    window = context.get_window(chunk.timestamp)
    # ... usar window para an√°lise contextual ...
```

### 4.2 Agrega√ß√£o Temporal de Categorias

**Problema**: Categorias isoladas podem ser ruidosas

**Solu√ß√£o**: Agregar categorias em janela temporal

**Algoritmo**:
```python
def aggregate_categories_temporal(
    self,
    window: List[Dict[str, Any]]
) -> Dict[str, Any]:
    """
    Agrega categorias em janela temporal.
    
    Returns:
        {
            'dominant_category': str,  # Categoria mais frequente
            'category_distribution': Dict[str, float],  # Distribui√ß√£o
            'stability': float,  # 0.0 (inst√°vel) a 1.0 (est√°vel)
            'trend': 'advancing' | 'stable' | 'regressing'
        }
    """
    if not window:
        return None
    
    # Contar ocorr√™ncias de cada categoria
    category_counts = {}
    for chunk in window:
        cat = chunk.get('sales_category')
        if cat:
            category_counts[cat] = category_counts.get(cat, 0) + 1
    
    # Calcular distribui√ß√£o
    total = sum(category_counts.values())
    distribution = {
        cat: count / total
        for cat, count in category_counts.items()
    }
    
    # Categoria dominante
    dominant = max(category_counts.items(), key=lambda x: x[1])[0] if category_counts else None
    
    # Estabilidade (quanto mais concentrada, mais est√°vel)
    if distribution:
        max_prob = max(distribution.values())
        stability = max_prob  # Simplificado
    else:
        stability = 0.0
    
    return {
        'dominant_category': dominant,
        'category_distribution': distribution,
        'stability': stability
    }
```

**Uso**: Backend usa categoria agregada ao inv√©s de categoria pontual

### 4.3 Tend√™ncia Sem√¢ntica ao Longo da Conversa

**Problema**: N√£o identifica se conversa est√° progredindo ou regredindo

**Solu√ß√£o**: Calcular tend√™ncia baseada em sequ√™ncia de categorias

**Mapeamento de Progress√£o**:
```python
CATEGORY_PROGRESSION = {
    'information_gathering': 1,
    'value_exploration': 2,
    'price_interest': 3,
    'decision_signal': 4,
    'closing_readiness': 5,
    'stalling': 0,  # Neutro
    'objection_soft': -1,
    'objection_hard': -2
}

def calculate_semantic_trend(
    self,
    window: List[Dict[str, Any]]
) -> Dict[str, Any]:
    """
    Calcula tend√™ncia sem√¢ntica da conversa.
    
    Returns:
        {
            'trend': 'advancing' | 'stable' | 'regressing',
            'trend_strength': float,  # 0.0 a 1.0
            'current_stage': int,  # Posi√ß√£o na progress√£o
            'velocity': float  # Mudan√ßa por minuto
        }
    """
    if len(window) < 2:
        return {'trend': 'stable', 'trend_strength': 0.0}
    
    # Mapear categorias para n√∫meros
    progression_values = [
        CATEGORY_PROGRESSION.get(chunk.get('sales_category'), 0)
        for chunk in window
        if chunk.get('sales_category')
    ]
    
    if len(progression_values) < 2:
        return {'trend': 'stable', 'trend_strength': 0.0}
    
    # Calcular tend√™ncia (regress√£o linear simples)
    import numpy as np
    x = np.arange(len(progression_values))
    y = np.array(progression_values)
    
    slope = np.polyfit(x, y, 1)[0]
    
    # Normalizar slope para [-1, 1]
    trend_strength = min(1.0, abs(slope) / 2.0)
    
    if slope > 0.1:
        trend = 'advancing'
    elif slope < -0.1:
        trend = 'regressing'
    else:
        trend = 'stable'
    
    return {
        'trend': trend,
        'trend_strength': trend_strength,
        'current_stage': progression_values[-1] if progression_values else 0,
        'velocity': slope
    }
```

**Uso no Backend**:
```typescript
if (semantic_trend.trend === 'advancing' && 
    semantic_trend.current_stage >= 3) {
  // Cliente progredindo para est√°gios avan√ßados
  // Gerar feedback positivo
}
```

### 4.4 Redu√ß√£o de Ru√≠do de Frases Isoladas

**Problema**: Frase isolada pode gerar classifica√ß√£o incorreta

**Solu√ß√£o**: Requerer consist√™ncia em janela temporal

**Estrat√©gia**:
1. Classificar chunk atual
2. Verificar se categoria √© consistente com hist√≥rico
3. Se inconsistente, usar categoria agregada do hist√≥rico
4. Se hist√≥rico insuficiente, usar chunk atual mas marcar como "low_confidence"

**Implementa√ß√£o**:
```python
def classify_with_context(
    self,
    text: str,
    context_window: List[Dict[str, Any]],
    min_consistency: float = 0.6
) -> Dict[str, Any]:
    """
    Classifica texto considerando contexto hist√≥rico.
    
    Args:
        text: Texto atual
        context_window: Janela de contexto hist√≥rico
        min_consistency: Consist√™ncia m√≠nima para aceitar categoria atual
    
    Returns:
        {
            'category': str,
            'confidence': float,
            'is_consistent': bool,
            'used_context': bool  # True se usou contexto ao inv√©s de chunk atual
        }
    """
    # Classificar chunk atual
    current_cat, current_conf, scores = self.classify_sales_category(text)
    
    if not context_window:
        return {
            'category': current_cat,
            'confidence': current_conf,
            'is_consistent': True,
            'used_context': False
        }
    
    # Agregar categorias do hist√≥rico
    aggregated = self.aggregate_categories_temporal(context_window)
    dominant_historical = aggregated['dominant_category']
    
    # Verificar consist√™ncia
    is_consistent = (
        current_cat == dominant_historical or
        aggregated['stability'] < 0.5  # Hist√≥rico inst√°vel, aceitar atual
    )
    
    if is_consistent or current_conf > 0.8:
        # Usar categoria atual
        return {
            'category': current_cat,
            'confidence': current_conf,
            'is_consistent': is_consistent,
            'used_context': False
        }
    else:
        # Usar categoria hist√≥rica (mais confi√°vel)
        return {
            'category': dominant_historical,
            'confidence': aggregated['stability'],
            'is_consistent': False,
            'used_context': True
        }
```

---

## 5Ô∏è‚É£ Sinais Sem√¢nticos Padronizados (Contrato Python ‚Üí Backend)

### 5.1 Estrutura de Sa√≠da Expandida

**Situa√ß√£o Atual**:
```json
{
  "sales_category": "price_interest",
  "sales_category_confidence": 0.85
}
```

**Estrutura Proposta**:
```json
{
  "semantic_signals": {
    "sales_category": {
      "primary": "price_interest",
      "secondary": ["information_gathering"],  // Multi-label quando aplic√°vel
      "confidence": 0.85,
      "intensity": 0.92,  // Score absoluto da melhor categoria
      "ambiguity": 0.15,   // Qu√£o amb√≠guo √© o texto (0=claro, 1=muito amb√≠guo)
      "scores": {
        "price_interest": 0.92,
        "information_gathering": 0.68,
        "value_exploration": 0.45,
        ...
      }
    },
    "context": {
      "trend": "advancing",  // advancing | stable | regressing
      "trend_strength": 0.75,
      "current_stage": 3,    // Posi√ß√£o na progress√£o (1-5)
      "stability": 0.82,     // Estabilidade da categoria na janela
      "consistency": true    // Se categoria atual √© consistente com hist√≥rico
    },
    "transitions": {
      "detected": true,
      "from_category": "value_exploration",
      "to_category": "price_interest",
      "transition_type": "advancing",
      "confidence": 0.88,
      "time_delta_ms": 15000
    },
    "flags": {
      "price_window_open": true,        // Janela de oportunidade para pre√ßo
      "decision_signal_strong": false,   // Sinal forte de decis√£o
      "objection_escalating": false,    // Obje√ß√£o piorando
      "conversation_stalling": false,    // Conversa estagnada
      "ready_to_close": false           // Pronto para fechar
    }
  }
}
```

### 5.2 Flags Sem√¢nticas Espec√≠ficas

**Proposta**: Flags booleanas que facilitam heur√≠sticas no backend

**Flags Propostas**:

```python
def generate_semantic_flags(
    self,
    category: str,
    confidence: float,
    intensity: float,
    context: Dict[str, Any],
    transitions: Optional[Dict[str, Any]]
) -> Dict[str, bool]:
    """
    Gera flags sem√¢nticas baseadas em an√°lise completa.
    
    Flags s√£o booleanas e facilitam decis√µes no backend.
    """
    flags = {}
    
    # Flag: Janela de oportunidade para pre√ßo
    flags['price_window_open'] = (
        category == 'price_interest' and
        confidence > 0.7 and
        intensity > 0.8
    )
    
    # Flag: Sinal forte de decis√£o
    flags['decision_signal_strong'] = (
        category in ['decision_signal', 'closing_readiness'] and
        confidence > 0.8 and
        intensity > 0.85
    )
    
    # Flag: Obje√ß√£o escalando
    flags['objection_escalating'] = (
        transitions and
        transitions['from_category'] == 'objection_soft' and
        transitions['to_category'] == 'objection_hard' and
        transitions['transition_type'] == 'regressing'
    )
    
    # Flag: Conversa estagnada
    flags['conversation_stalling'] = (
        context.get('trend') == 'stable' and
        context.get('stability', 0) > 0.9 and
        category == 'stalling'
    )
    
    # Flag: Pronto para fechar
    flags['ready_to_close'] = (
        category == 'closing_readiness' and
        confidence > 0.85 and
        context.get('trend') == 'advancing' and
        context.get('current_stage', 0) >= 4
    )
    
    return flags
```

**Uso no Backend**:
```typescript
if (semantic_signals.flags.price_window_open) {
  // Gerar feedback: "Agora √© o momento de falar sobre pre√ßo"
}

if (semantic_signals.flags.objection_escalating) {
  // Gerar feedback urgente sobre obje√ß√£o
}

if (semantic_signals.flags.ready_to_close) {
  // Gerar feedback: "Cliente pronto para fechar - acelerar!"
}
```

### 5.3 Intensidade do Sinal

**Proposta**: Score absoluto da melhor categoria (diferente de confian√ßa)

**Diferen√ßa**:
- **Confian√ßa**: Diferen√ßa relativa entre melhor e segunda melhor (0-1)
- **Intensidade**: Score absoluto da melhor categoria (0-1)

**Exemplo**:
```
Caso 1:
  Melhor: 0.9, Segunda: 0.2
  Confian√ßa: (0.9-0.2)/0.9 = 0.78 (alta)
  Intensidade: 0.9 (alta)

Caso 2:
  Melhor: 0.5, Segunda: 0.1
  Confian√ßa: (0.5-0.1)/0.5 = 0.8 (alta)
  Intensidade: 0.5 (m√©dia)
```

**Uso**: Backend pode usar intensidade para priorizar feedbacks

### 5.4 Dire√ß√£o da Conversa

**Proposta**: Indicador de progress√£o/regress√£o

**Valores**:
- `advancing`: Cliente progredindo (ex: value ‚Üí price ‚Üí decision)
- `stable`: Sem mudan√ßa significativa
- `regressing`: Cliente regredindo (ex: decision ‚Üí objection)

**C√°lculo**: Baseado em tend√™ncia sem√¢ntica (se√ß√£o 4.3)

**Uso no Backend**:
```typescript
if (semantic_signals.context.trend === 'regressing') {
  // Gerar alerta: "Cliente regredindo - requer aten√ß√£o"
}
```

---

## 6Ô∏è‚É£ Heur√≠sticas no Backend (Node/NestJS)

### 6.1 Combina√ß√£o de Sinais Sem√¢nticos + Tempo + Hist√≥rico

**Estrat√©gia**: Backend combina m√∫ltiplos sinais para gerar feedback confi√°vel

**Heur√≠stica Proposta**:
```typescript
function shouldGenerateSalesFeedback(
  state: ParticipantState,
  semanticSignals: SemanticSignals,
  now: number
): boolean {
  // 1. Verificar cooldown global
  if (inGlobalCooldown(state, now, 30000)) { // 30s
    return false;
  }
  
  // 2. Verificar flags sem√¢nticas fortes
  if (semanticSignals.flags.decision_signal_strong ||
      semanticSignals.flags.objection_escalating ||
      semanticSignals.flags.ready_to_close) {
    return true; // Flags fortes sempre geram feedback
  }
  
  // 3. Verificar consist√™ncia temporal
  const recentCategories = getRecentCategories(state, 60000); // √öltimo minuto
  const consistency = calculateConsistency(
    semanticSignals.sales_category.primary,
    recentCategories
  );
  
  if (consistency < 0.6 && semanticSignals.context.consistency === false) {
    return false; // Muito inconsistente, n√£o gerar feedback
  }
  
  // 4. Verificar confian√ßa e intensidade
  if (semanticSignals.sales_category.confidence < 0.6 ||
      semanticSignals.sales_category.intensity < 0.6) {
    return false; // Muito incerto
  }
  
  // 5. Verificar ambiguidade
  if (semanticSignals.sales_category.ambiguity > 0.7) {
    return false; // Muito amb√≠guo
  }
  
  return true;
}
```

### 6.2 Evitar Feedbacks Prematuros

**Problema**: Feedback gerado muito cedo pode ser baseado em ru√≠do

**Solu√ß√£o**: Requerer estabilidade temporal

**Heur√≠stica**:
```typescript
function isFeedbackPremature(
  state: ParticipantState,
  semanticSignals: SemanticSignals,
  now: number
): boolean {
  // Requerer pelo menos 2 chunks com mesma categoria
  const recentCategories = getRecentCategories(state, 30000); // 30s
  const sameCategoryCount = recentCategories.filter(
    cat => cat === semanticSignals.sales_category.primary
  ).length;
  
  if (sameCategoryCount < 2 && !semanticSignals.flags.decision_signal_strong) {
    return true; // Muito prematuro
  }
  
  // Requerer estabilidade m√≠nima
  if (semanticSignals.context.stability < 0.5) {
    return true; // Muito inst√°vel
  }
  
  return false;
}
```

### 6.3 Gerar Feedbacks Acion√°veis e Contextualizados

**Estrat√©gia**: Mensagens espec√≠ficas baseadas em combina√ß√£o de sinais

**Exemplos de Heur√≠sticas**:

```typescript
function generateSalesFeedback(
  state: ParticipantState,
  semanticSignals: SemanticSignals
): FeedbackEventPayload | null {
  // Heur√≠stica 1: Janela de pre√ßo
  if (semanticSignals.flags.price_window_open &&
      semanticSignals.context.trend === 'advancing') {
    return {
      type: 'sales_opportunity',
      severity: 'info',
      message: 'Agora √© o momento ideal para apresentar o pre√ßo',
      tips: [
        'Cliente demonstrou interesse consistente',
        'Conversa progredindo positivamente',
        'Confian√ßa alta na classifica√ß√£o'
      ]
    };
  }
  
  // Heur√≠stica 2: Obje√ß√£o escalando
  if (semanticSignals.flags.objection_escalating) {
    return {
      type: 'sales_alert',
      severity: 'warning',
      message: 'Obje√ß√£o do cliente est√° piorando - requer abordagem diferente',
      tips: [
        'Cliente regrediu de obje√ß√£o leve para forte',
        'Considerar mudan√ßa de estrat√©gia',
        'Focar em entender preocupa√ß√µes espec√≠ficas'
      ]
    };
  }
  
  // Heur√≠stica 3: Pronto para fechar
  if (semanticSignals.flags.ready_to_close &&
      semanticSignals.context.current_stage >= 4) {
    return {
      type: 'sales_opportunity',
      severity: 'info',
      message: 'Cliente demonstra prontid√£o para fechar - acelerar processo',
      tips: [
        'M√∫ltiplos sinais de fechamento detectados',
        'Conversa progredindo consistentemente',
        'Momento ideal para proposta final'
      ]
    };
  }
  
  // Heur√≠stica 4: Conversa estagnada
  if (semanticSignals.flags.conversation_stalling &&
      semanticSignals.context.trend === 'stable') {
    return {
      type: 'sales_alert',
      severity: 'info',
      message: 'Conversa estagnada - considerar criar urg√™ncia',
      tips: [
        'Cliente protelando decis√£o',
        'Considerar oferecer incentivo ou deadline',
        'Revisar valor proposto'
      ]
    };
  }
  
  return null;
}
```

### 6.4 Prioriza√ß√£o de Feedbacks

**Problema**: M√∫ltiplos feedbacks podem ser gerados simultaneamente

**Solu√ß√£o**: Sistema de prioridades

**Prioridades**:
1. **Cr√≠tica**: `objection_escalating`, `ready_to_close`
2. **Alta**: `price_window_open`, `decision_signal_strong`
3. **M√©dia**: `conversation_stalling`, transi√ß√µes importantes
4. **Baixa**: Categorias est√°veis sem flags

**Implementa√ß√£o**:
```typescript
const FEEDBACK_PRIORITIES = {
  'objection_escalating': 10,
  'ready_to_close': 10,
  'price_window_open': 8,
  'decision_signal_strong': 8,
  'conversation_stalling': 5,
  'default': 3
};

function prioritizeFeedback(feedback: FeedbackEventPayload): number {
  // Extrair tipo do feedback
  const type = feedback.type;
  return FEEDBACK_PRIORITIES[type] || FEEDBACK_PRIORITIES.default;
}

// No aggregator:
const feedbacks = [
  generateSalesFeedback(state, signals),
  generateEmotionalFeedback(state, ctx),
  // ... outros feedbacks
].filter(f => f !== null);

if (feedbacks.length > 0) {
  // Selecionar feedback de maior prioridade
  const topFeedback = feedbacks.reduce((a, b) => 
    prioritizeFeedback(a) > prioritizeFeedback(b) ? a : b
  );
  
  this.delivery.publishToHosts(meetingId, topFeedback);
}
```

---

## 7Ô∏è‚É£ Performance e Escalabilidade

### 7.1 Cache de Embeddings

**Situa√ß√£o Atual**: ‚úÖ Cache de exemplos implementado

**Melhorias Propostas**:

**Cache de Embeddings de Textos**:
```python
class EmbeddingCache:
    """
    Cache de embeddings de textos para evitar rec√°lculo.
    """
    def __init__(self, max_size: int = 1000, ttl_seconds: int = 3600):
        self.cache: Dict[str, Tuple[np.ndarray, int]] = {}
        self.max_size = max_size
        self.ttl_seconds = ttl_seconds
    
    def get(self, text: str) -> Optional[np.ndarray]:
        """Retorna embedding se em cache e v√°lido"""
        text_hash = self._hash_text(text)
        if text_hash in self.cache:
            embedding, timestamp = self.cache[text_hash]
            if time.time() - timestamp < self.ttl_seconds:
                return embedding
            else:
                del self.cache[text_hash]
        return None
    
    def set(self, text: str, embedding: np.ndarray):
        """Armazena embedding no cache"""
        text_hash = self._hash_text(text)
        if len(self.cache) >= self.max_size:
            # Remover mais antigo (LRU simplificado)
            oldest = min(self.cache.items(), key=lambda x: x[1][1])
            del self.cache[oldest[0]]
        
        self.cache[text_hash] = (embedding, time.time())
```

**Uso**: Cachear embeddings de chunks para compara√ß√µes hist√≥ricas

### 7.2 Batch Processing

**Problema**: Processar m√∫ltiplos textos sequencialmente √© lento

**Solu√ß√£o**: Processar em batch quando poss√≠vel

**Implementa√ß√£o**:
```python
def classify_sales_category_batch(
    self,
    texts: List[str],
    min_confidence: float = 0.3
) -> List[Tuple[Optional[str], float, Dict[str, float]]]:
    """
    Classifica m√∫ltiplos textos em batch (mais eficiente).
    
    Performance: ~2x mais r√°pido que processar sequencialmente
    """
    if not self._sales_examples_loaded:
        self._load_sales_category_examples_embeddings()
    
    # Gerar embeddings em batch
    text_embeddings = self.sbert_model.encode(
        texts,
        convert_to_numpy=True,
        normalize_embeddings=True,
        show_progress_bar=False,
        batch_size=32
    )
    
    results = []
    for text_embedding in text_embeddings:
        # ... c√°lculo de similaridade ...
        results.append((category, confidence, scores))
    
    return results
```

**Uso**: Quando processar hist√≥rico ou m√∫ltiplos chunks

### 7.3 Limites de Lat√™ncia Aceit√°veis

**Metas de Performance**:

| Opera√ß√£o | Lat√™ncia Aceit√°vel | Lat√™ncia Ideal |
|----------|-------------------|----------------|
| Primeira an√°lise (com contexto) | < 1.5s | < 1.0s |
| An√°lises subsequentes | < 100ms | < 50ms |
| Classifica√ß√£o batch (10 textos) | < 500ms | < 300ms |
| C√°lculo de tend√™ncia | < 50ms | < 20ms |

**Estrat√©gias**:
- Cache agressivo
- Processamento ass√≠ncrono quando poss√≠vel
- Limitar tamanho de janelas de contexto
- Pr√©-calcular m√©tricas quando poss√≠vel

### 7.4 Estrat√©gia CPU-First com GPU Opcional

**Situa√ß√£o Atual**: CPU-only

**Estrat√©gia**:
1. **Curto Prazo**: Otimizar para CPU
   - Usar modelos leves
   - Cache agressivo
   - Batch processing quando poss√≠vel

2. **M√©dio Prazo**: Suporte opcional a GPU
   - Detectar GPU automaticamente
   - Usar GPU se dispon√≠vel
   - Fallback para CPU

3. **Longo Prazo**: Avaliar necessidade de GPU
   - Se lat√™ncia CPU for aceit√°vel, manter CPU
   - Se necess√°rio, considerar GPU dedicada

**Implementa√ß√£o**:
```python
# J√° implementado: device detection
if self.device == "cuda" and torch.cuda.is_available():
    self.model = self.model.to("cuda")
```

### 7.5 Separa√ß√£o Clara: Transcri√ß√£o vs An√°lise Sem√¢ntica

**Arquitetura Atual**: ‚úÖ J√° separado

**Melhorias**:
- Garantir que falha em an√°lise sem√¢ntica n√£o bloqueia transcri√ß√£o
- Processar an√°lise sem√¢ntica de forma ass√≠ncrona quando poss√≠vel
- Priorizar transcri√ß√£o sobre an√°lise (transcri√ß√£o √© cr√≠tica)

---

## 8Ô∏è‚É£ Observabilidade e Qualidade

### 8.1 M√©tricas Sem√¢nticas

**M√©tricas Propostas**:

```python
class SemanticMetrics:
    """
    Coleta m√©tricas de qualidade da classifica√ß√£o sem√¢ntica.
    """
    def __init__(self):
        self.metrics = {
            'total_classifications': 0,
            'successful_classifications': 0,
            'failed_classifications': 0,
            'avg_confidence': 0.0,
            'avg_intensity': 0.0,
            'avg_ambiguity': 0.0,
            'category_distribution': {},
            'transition_count': 0,
            'high_confidence_rate': 0.0  # % com confian√ßa > 0.7
        }
    
    def record_classification(
        self,
        category: Optional[str],
        confidence: float,
        intensity: float,
        ambiguity: float
    ):
        """Registra uma classifica√ß√£o"""
        self.metrics['total_classifications'] += 1
        
        if category:
            self.metrics['successful_classifications'] += 1
            self.metrics['category_distribution'][category] = \
                self.metrics['category_distribution'].get(category, 0) + 1
        else:
            self.metrics['failed_classifications'] += 1
        
        # Atualizar m√©dias (m√©dia m√≥vel exponencial)
        alpha = 0.1
        self.metrics['avg_confidence'] = (
            alpha * confidence + (1 - alpha) * self.metrics['avg_confidence']
        )
        self.metrics['avg_intensity'] = (
            alpha * intensity + (1 - alpha) * self.metrics['avg_intensity']
        )
        self.metrics['avg_ambiguity'] = (
            alpha * ambiguity + (1 - alpha) * self.metrics['avg_ambiguity']
        )
        
        if confidence > 0.7:
            self.metrics['high_confidence_rate'] = (
                self.metrics['high_confidence_rate'] * 0.99 + 0.01
            )
    
    def get_metrics(self) -> Dict[str, Any]:
        """Retorna m√©tricas atuais"""
        return self.metrics.copy()
```

**Exposi√ß√£o**: Endpoint `/metrics` no FastAPI

### 8.2 Logs Explic√°veis

**Problema**: Logs n√£o explicam por que um sinal foi emitido

**Solu√ß√£o**: Logs estruturados com contexto completo

**Formato Proposto**:
```python
logger.info(
    "Semantic signal generated",
    signal_type="price_window_open",
    reasoning={
        "category": "price_interest",
        "confidence": 0.85,
        "intensity": 0.92,
        "ambiguity": 0.15,
        "context_consistency": True,
        "temporal_stability": 0.82,
        "trend": "advancing",
        "flags_triggered": ["price_window_open"],
        "why": "High confidence price_interest with advancing trend and low ambiguity"
    }
)
```

**Uso**: Facilita debugging e valida√ß√£o manual

### 8.3 Estrat√©gia de Valida√ß√£o Manual

**Proposta**: Dashboard de valida√ß√£o

**Funcionalidades**:
1. Visualizar classifica√ß√µes em tempo real
2. Marcar classifica√ß√µes como corretas/incorretas
3. Ver m√©tricas de qualidade
4. Ajustar thresholds baseado em feedback

**Implementa√ß√£o Futura**:
- Endpoint `/validate` para marcar classifica√ß√µes
- Armazenar valida√ß√µes para an√°lise
- Ajustar exemplos baseado em feedback

### 8.4 Ajustes Cont√≠nuos via Dados Reais

**Estrat√©gia**: Coletar dados e melhorar iterativamente

**Coleta de Dados**:
1. Logs de classifica√ß√µes (an√¥nimos)
2. Valida√ß√µes manuais quando poss√≠vel
3. M√©tricas de uso (quais categorias mais comuns)

**Melhorias Baseadas em Dados**:
1. Ajustar exemplos de refer√™ncia
2. Ajustar thresholds de confian√ßa
3. Adicionar novas categorias se necess√°rio
4. Remover categorias pouco usadas

---

## 9Ô∏è‚É£ Roadmap Incremental

### Curto Prazo (1-2 semanas) - Quick Wins

**Objetivo**: Melhorias r√°pidas com alto impacto

**Itens**:

1. **Expandir Exemplos de Refer√™ncia**
   - Adicionar 5 exemplos por categoria (80 ‚Üí 120 total)
   - Incluir varia√ß√µes regionais
   - **Esfor√ßo**: 4 horas
   - **Impacto**: +10-15% precis√£o

2. **Adicionar Score de Ambiguidade**
   - Implementar c√°lculo de ambiguidade
   - Incluir no retorno
   - **Esfor√ßo**: 2 horas
   - **Impacto**: Reduz falsos positivos

3. **Adicionar Intensidade do Sinal**
   - Score absoluto da melhor categoria
   - Incluir no retorno
   - **Esfor√ßo**: 1 hora
   - **Impacto**: Backend pode priorizar melhor

4. **Melhorar Logging**
   - Logs mais explic√°veis
   - Incluir reasoning
   - **Esfor√ßo**: 2 horas
   - **Impacto**: Melhor debugging

5. **Flags Sem√¢nticas B√°sicas**
   - Implementar 3-5 flags principais
   - `price_window_open`, `decision_signal_strong`, `ready_to_close`
   - **Esfor√ßo**: 4 horas
   - **Impacto**: Backend pode gerar feedbacks mais espec√≠ficos

**Total**: ~13 horas de desenvolvimento

### M√©dio Prazo (1-2 meses)

**Objetivo**: Funcionalidades mais complexas

**Itens**:

1. **An√°lise de Contexto Conversacional**
   - Implementar `ConversationContext`
   - Janelas temporais
   - Agrega√ß√£o temporal
   - **Esfor√ßo**: 16 horas
   - **Impacto**: Reduz ru√≠do, detecta padr√µes

2. **Detec√ß√£o de Transi√ß√µes**
   - Comparar categoria atual com hist√≥rico
   - Detectar progress√£o/regress√£o
   - **Esfor√ßo**: 8 horas
   - **Impacto**: Detecta mudan√ßas importantes

3. **Tend√™ncia Sem√¢ntica**
   - Calcular tend√™ncia ao longo do tempo
   - Dire√ß√£o da conversa
   - **Esfor√ßo**: 6 horas
   - **Impacto**: Backend pode gerar feedbacks contextuais

4. **Classifica√ß√£o Multi-Label**
   - Permitir m√∫ltiplas categorias
   - **Esfor√ßo**: 8 horas
   - **Impacto**: Captura casos complexos

5. **Heur√≠sticas no Backend**
   - Implementar `shouldGenerateSalesFeedback`
   - Prioriza√ß√£o de feedbacks
   - **Esfor√ßo**: 12 horas
   - **Impacto**: Feedbacks mais confi√°veis

6. **M√©tricas e Observabilidade**
   - Coletar m√©tricas sem√¢nticas
   - Endpoint `/metrics`
   - **Esfor√ßo**: 6 horas
   - **Impacto**: Visibilidade de qualidade

**Total**: ~56 horas de desenvolvimento

### Longo Prazo (3-6 meses)

**Objetivo**: Otimiza√ß√µes e melhorias avan√ßadas

**Itens**:

1. **Fine-tuning do Modelo SBERT**
   - Coletar dataset de reuni√µes reais
   - Anotar manualmente
   - Fine-tune para dom√≠nio espec√≠fico
   - **Esfor√ßo**: 40+ horas
   - **Impacto**: +20-30% precis√£o

2. **Cache de Embeddings de Textos**
   - Implementar cache LRU
   - Reduzir rec√°lculos
   - **Esfor√ßo**: 4 horas
   - **Impacto**: Melhor performance

3. **Batch Processing**
   - Processar m√∫ltiplos textos em batch
   - **Esfor√ßo**: 6 horas
   - **Impacto**: 2x mais r√°pido para hist√≥rico

4. **Dashboard de Valida√ß√£o**
   - Interface para validar classifica√ß√µes
   - Coletar feedback
   - **Esfor√ßo**: 20 horas
   - **Impacto**: Melhorar qualidade iterativamente

5. **Ajustes Baseados em Dados**
   - Analisar dados coletados
   - Ajustar exemplos e thresholds
   - **Esfor√ßo**: Cont√≠nuo
   - **Impacto**: Melhoria cont√≠nua

**Total**: ~70+ horas de desenvolvimento

### O Que N√ÉO Fazer Agora (Anti-Overengineering)

**Evitar**:
- ‚ùå Modelos muito complexos (ex: LLMs grandes)
- ‚ùå Fine-tuning sem dados reais suficientes
- ‚ùå GPU dedicada antes de otimizar CPU
- ‚ùå Sistema de ML completo (manter simples)
- ‚ùå Over-engineering de cache (atual √© suficiente)
- ‚ùå Muitas categorias novas sem valida√ß√£o

**Princ√≠pio**: Implementar apenas o necess√°rio, validar com dados reais, iterar.

---

## üîü Decis√µes T√©cnicas Principais

### Decis√£o 1: Manter SBERT Atual vs Fine-tuning

**Decis√£o**: Manter modelo atual por agora, avaliar fine-tuning ap√≥s coletar dados

**Raz√£o**: Fine-tuning requer dataset anotado, que ainda n√£o temos. Melhor validar abordagem atual primeiro.

### Decis√£o 2: Contexto em Python vs Backend

**Decis√£o**: Contexto em Python (janelas temporais), hist√≥rico completo no backend

**Raz√£o**: Python j√° tem embeddings, mais eficiente calcular similaridades l√°. Backend mant√©m hist√≥rico completo para heur√≠sticas complexas.

### Decis√£o 3: Multi-Label vs Single-Label

**Decis√£o**: Implementar multi-label opcional (m√©dio prazo)

**Raz√£o**: √ötil para casos complexos, mas n√£o cr√≠tico. Pode adicionar depois.

### Decis√£o 4: Flags vs Scores Diretos

**Decis√£o**: Ambos - flags para facilitar heur√≠sticas, scores para flexibilidade

**Raz√£o**: Flags facilitam c√≥digo no backend, scores permitem heur√≠sticas customizadas.

### Decis√£o 5: CPU-First vs GPU-First

**Decis√£o**: CPU-first com suporte opcional a GPU

**Raz√£o**: CPU √© suficiente para lat√™ncia aceit√°vel, GPU adiciona complexidade e custo.

---

## üìä M√©tricas de Sucesso

### M√©tricas T√©cnicas

- **Precis√£o de Classifica√ß√£o**: > 80% (validado manualmente)
- **Lat√™ncia P95**: < 100ms (an√°lises subsequentes)
- **Taxa de Falsos Positivos**: < 10%
- **Cobertura de Categorias**: Todas as 8 categorias detect√°veis

### M√©tricas de Neg√≥cio

- **Feedbacks Gerados**: Taxa adequada (n√£o muito, n√£o pouco)
- **Qualidade dos Feedbacks**: Validado por vendedores
- **A√ß√£o dos Vendedores**: Feedbacks levam a a√ß√µes

### M√©tricas de Qualidade

- **Confian√ßa M√©dia**: > 0.7
- **Ambiguidade M√©dia**: < 0.4
- **Taxa de Alta Confian√ßa**: > 60%

---

## üéØ Conclus√£o

Este roadmap fornece um plano incremental e pragm√°tico para evoluir o sistema de an√°lise sem√¢ntica de vendas. As melhorias s√£o projetadas para:

1. **Aumentar Robustez**: Contexto e agrega√ß√£o temporal
2. **Melhorar Precis√£o**: Mais exemplos, m√©tricas de qualidade
3. **Facilitar Heur√≠sticas**: Flags e sinais estruturados
4. **Manter Simplicidade**: Incremental, sem over-engineering

**Pr√≥ximo Passo Recomendado**: Implementar quick wins (curto prazo) e validar com dados reais antes de avan√ßar para melhorias mais complexas.

---

**Documento criado em**: 2025-01-XX  
**Vers√£o**: 1.0  
**Status**: Proposta T√©cnica

