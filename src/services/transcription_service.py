"""
Servi√ßo de transcri√ß√£o de √°udio usando faster-whisper.
Recebe chunks de √°udio WAV e retorna transcri√ß√µes em texto.

faster-whisper √© uma implementa√ß√£o otimizada do Whisper que:
- √â mais r√°pida (at√© 4x mais r√°pida que openai-whisper)
- Usa menos mem√≥ria
- Suporta os mesmos modelos (tiny, base, small, medium, large)
- Funciona melhor em CPU com compute_type="int8"
"""

import io
import asyncio
import time
import structlog
from faster_whisper import WhisperModel
import numpy as np
from typing import Optional, Dict, Any, List
from concurrent.futures import ThreadPoolExecutor
from ..config import Config

logger = structlog.get_logger()


class TranscriptionService:
    """
    Servi√ßo de transcri√ß√£o de √°udio usando faster-whisper.
    
    faster-whisper √© uma implementa√ß√£o otimizada do Whisper da OpenAI,
    otimizada para m√∫ltiplos idiomas incluindo portugu√™s.
    
    Caracter√≠sticas:
    - Suporta m√∫ltiplos idiomas (portugu√™s inclu√≠do)
    - Modelos leves dispon√≠veis (tiny, base, small, medium, large)
    - Funciona em CPU e GPU
    - Mais r√°pido e eficiente que openai-whisper
    - Lazy loading do modelo (carrega apenas quando necess√°rio)
    """
    
    def __init__(self):
        """
        Inicializa servi√ßo de transcri√ß√£o.
        O modelo Whisper ser√° carregado apenas na primeira transcri√ß√£o (lazy loading).
        """
        self.model = None
        self._loaded = False
        self.model_name = Config.WHISPER_MODEL_NAME
        self.device = Config.WHISPER_DEVICE
        self.language = Config.WHISPER_LANGUAGE
        self.task = Config.WHISPER_TASK
        
        # faster-whisper compute_type: "int8" para CPU (mais r√°pido), "float16" para GPU
        import os
        compute_type_env = os.getenv('WHISPER_COMPUTE_TYPE', '')
        if compute_type_env:
            self.compute_type = compute_type_env
        else:
            # Auto-detect: int8 para CPU, float16 para GPU
            self.compute_type = "int8" if self.device == "cpu" else "float16"
        
        # Log expl√≠cito do modelo que ser√° usado
        env_value = os.getenv('WHISPER_MODEL_NAME', 'NOT_SET')
        logger.info(
            "üîç [TRANSCRI√á√ÉO] Configura√ß√£o do modelo faster-whisper",
            env_var_WHISPER_MODEL_NAME=env_value,
            config_WHISPER_MODEL_NAME=self.model_name,
            device=self.device,
            compute_type=self.compute_type,
            language=self.language,
            note="faster-whisper √© mais r√°pido que openai-whisper"
        )
        
        # Sem√°foro para limitar transcri√ß√µes simult√¢neas
        # faster-whisper √© mais eficiente, mas ainda limitamos a 1 transcri√ß√£o por vez
        # para evitar sobrecarga e garantir que cada transcri√ß√£o tenha recursos completos
        try:
            self._transcription_semaphore = asyncio.Semaphore(1)
        except RuntimeError:
            # Se n√£o houver event loop, criar None e inicializar depois
            self._transcription_semaphore = None
        self._active_transcriptions = 0
        
        # Dura√ß√£o m√≠nima de √°udio para transcri√ß√£o (em segundos)
        # Chunks muito pequenos (< 0.5s) s√£o ignorados pois:
        # 1. faster-whisper funciona melhor com √°udio mais longo
        # 2. Reduz carga desnecess√°ria no CPU
        # 3. Melhora qualidade da transcri√ß√£o
        self._min_audio_duration_sec = 0.5
        
        # ThreadPoolExecutor para executar faster-whisper em thread separada
        # faster-whisper √© mais r√°pido mas ainda bloqueante, ent√£o executamos em thread separada
        # para n√£o bloquear o event loop do asyncio
        self._executor = ThreadPoolExecutor(max_workers=1)
        
        logger.info(
            "‚úÖ [SERVI√áO] TranscriptionService inicializado",
            model=self.model_name,
            device=self.device,
            language=self.language,
            max_concurrent_transcriptions=1,
            min_audio_duration_sec=self._min_audio_duration_sec
        )
    
    def _load_model(self):
        """
        Carrega modelo faster-whisper (lazy loading).
        
        Modelos dispon√≠veis (do menor ao maior):
        - tiny: ~39M par√¢metros, mais r√°pido, menos preciso
        - base: ~74M par√¢metros, bom equil√≠brio
        - small: ~244M par√¢metros, mais preciso
        - medium: ~769M par√¢metros, muito preciso
        - large: ~1550M par√¢metros, mais preciso, mais lento
        
        O modelo escolhido (base por padr√£o) oferece bom equil√≠brio
        entre velocidade e precis√£o para transcri√ß√µes em tempo real.
        
        faster-whisper √© mais r√°pido que openai-whisper, especialmente em CPU
        com compute_type="int8".
        """
        if self._loaded:
            logger.debug("Modelo faster-whisper j√° carregado", model=self.model_name)
            return
        
        logger.info(
            "üîÑ [TRANSCRI√á√ÉO] Carregando modelo faster-whisper",
            model=self.model_name,
            device=self.device,
            compute_type=self.compute_type
        )
        
        load_start = time.perf_counter()
        
        try:
            # faster-whisper aceita "cpu" ou "cuda" diretamente
            # Ele mesmo verifica se CUDA est√° dispon√≠vel, ent√£o n√£o precisamos verificar manualmente
            device = self.device
            compute_type = self.compute_type
            
            # Tentar carregar modelo faster-whisper
            # O modelo ser√° baixado automaticamente na primeira execu√ß√£o
            # e armazenado em cache para uso futuro
            try:
                self.model = WhisperModel(
                    self.model_name,
                    device=device,
                    compute_type=compute_type
                )
            except (RuntimeError, ValueError) as cuda_error:
                # Se CUDA n√£o estiver dispon√≠vel ou houver erro, tentar com CPU
                if device == "cuda":
                    logger.warn(
                        "CUDA requested but not available, falling back to CPU",
                        error=str(cuda_error)
                    )
                    device = "cpu"
                    compute_type = "int8"
                    self.compute_type = "int8"
                    # Tentar novamente com CPU
                    self.model = WhisperModel(
                        self.model_name,
                        device=device,
                        compute_type=compute_type
                    )
                else:
                    # Re-raise se n√£o for problema de CUDA
                    raise
            
            self._loaded = True
            load_latency_ms = (time.perf_counter() - load_start) * 1000
            
            logger.info(
                "‚úÖ [TRANSCRI√á√ÉO] Modelo faster-whisper carregado com sucesso",
                model=self.model_name,
                device=device,
                compute_type=self.compute_type,
                language=self.language,
                load_time_ms=round(load_latency_ms, 2),
                note="faster-whisper √© mais r√°pido que openai-whisper"
            )
            
        except Exception as e:
            load_latency_ms = (time.perf_counter() - load_start) * 1000
            logger.error(
                "‚ùå [TRANSCRI√á√ÉO] Falha ao carregar modelo faster-whisper",
                error=str(e),
                error_type=type(e).__name__,
                model=self.model_name,
                load_time_ms=round(load_latency_ms, 2)
            )
            raise
    
    async def transcribe_audio(
        self,
        audio_data: bytes,
        sample_rate: int = 16000,
        language: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Transcreve √°udio WAV para texto usando Whisper.
        
        Como funciona:
        ==============
        1. O √°udio WAV √© decodificado para array numpy
        2. O Whisper processa o √°udio em chunks sobrepostos
        3. O modelo gera tokens de texto correspondentes ao √°udio
        4. Os tokens s√£o decodificados para texto final
        
        Par√¢metros:
        ===========
        - audio_data: Bytes do arquivo WAV (incluindo header)
        - sample_rate: Taxa de amostragem do √°udio (Hz)
        - language: Idioma do √°udio (None = auto-detect, 'pt' = portugu√™s)
        
        Retorna:
        ========
        Dict com:
        {
            'text': str,              # Texto transcrito
            'language': str,           # Idioma detectado
            'segments': List[Dict],    # Segmentos com timestamps
            'confidence': float        # Confian√ßa m√©dia (0-1)
        }
        
        Exemplo:
        ========
        result = service.transcribe_audio(wav_bytes, sample_rate=16000, language='pt')
        print(result['text'])  # "Ol√°, como voc√™ est√°?"
        """
        # Carregar modelo de forma ass√≠ncrona se necess√°rio
        if not self._loaded:
            logger.info("üîÑ [TRANSCRI√á√ÉO] Modelo n√£o carregado, carregando agora...")
            loop = asyncio.get_running_loop()
            await loop.run_in_executor(
                self._executor,
                self._load_model
            )
            logger.info("‚úÖ [TRANSCRI√á√ÉO] Modelo carregado, prosseguindo com transcri√ß√£o")
        
        # Inicializar sem√°foro se ainda n√£o foi criado (fallback)
        if self._transcription_semaphore is None:
            self._transcription_semaphore = asyncio.Semaphore(1)
        
        try:
            logger.debug(
                "üîç [TRANSCRI√á√ÉO] Decodificando WAV",
                audio_size_bytes=len(audio_data),
                expected_sample_rate=sample_rate
            )
            
            # Decodificar WAV para array numpy
            # O Whisper espera √°udio como array numpy float32 normalizado (-1 a 1)
            audio_array = self._decode_wav(audio_data, sample_rate)
            
            if audio_array is None or len(audio_array) == 0:
                logger.warn(
                    "‚ö†Ô∏è [TRANSCRI√á√ÉO] √Åudio vazio ou inv√°lido",
                    audio_size_bytes=len(audio_data)
                )
                return {
                    'text': '',
                    'language': language or self.language,
                    'segments': [],
                    'confidence': 0.0
                }
            
            # Filtrar chunks muito pequenos
            audio_duration_sec = len(audio_array) / sample_rate
            if audio_duration_sec < self._min_audio_duration_sec:
                logger.debug(
                    "‚è≠Ô∏è [TRANSCRI√á√ÉO] Chunk muito pequeno, ignorando",
                    audio_duration_sec=round(audio_duration_sec, 2),
                    min_duration_sec=self._min_audio_duration_sec,
                    audio_samples=len(audio_array)
                )
                return {
                    'text': '',
                    'language': language or self.language,
                    'segments': [],
                    'confidence': 0.0
                }
            
            logger.debug(
                "‚úÖ [TRANSCRI√á√ÉO] WAV decodificado",
                audio_samples=len(audio_array),
                audio_length_sec=round(len(audio_array) / sample_rate, 2)
            )
            
            # Configurar par√¢metros de transcri√ß√£o para faster-whisper
            # faster-whisper tem par√¢metros ligeiramente diferentes
            transcribe_options = {
                'language': language or self.language,
                'task': self.task,  # 'transcribe' ou 'translate'
                'temperature': 0.0,  # Temperatura 0 = mais determin√≠stico e preciso
                'condition_on_previous_text': False,  # Evitar repeti√ß√µes quando texto anterior √© ruim
                'compression_ratio_threshold': 2.4,  # Detectar e filtrar repeti√ß√µes
                'log_prob_threshold': -1.0,  # Filtrar segmentos com baixa confian√ßa (note: log_prob, n√£o logprob)
                'no_speech_threshold': 0.3,  # Threshold mais baixo (mais permissivo) - padr√£o era 0.6
                'beam_size': 5,  # Beam search size (padr√£o √© 5)
                # VAD desabilitado - estava removendo todo o √°udio v√°lido
                # O VAD do faster-whisper pode ser muito agressivo com √°udio de chamadas
                'vad_filter': False,  # Desabilitar VAD para evitar remo√ß√£o de √°udio v√°lido
            }
            
            audio_length_sec = len(audio_array) / sample_rate
            logger.info(
                "üéôÔ∏è [TRANSCRI√á√ÉO] Iniciando transcri√ß√£o com Whisper",
                audio_length_sec=round(audio_length_sec, 2),
                audio_samples=len(audio_array),
                sample_rate=sample_rate,
                language=transcribe_options['language'],
                model=self.model_name,
                device=self.device
            )
            
            # Transcrever √°udio em thread separada para n√£o bloquear event loop
            # Whisper √© CPU/GPU intensivo e pode demorar alguns segundos
            # Usar get_running_loop() para Python 3.7+ (mais seguro)
            try:
                loop = asyncio.get_running_loop()
            except RuntimeError:
                # Fallback para get_event_loop() se n√£o houver loop rodando
                loop = asyncio.get_event_loop()
            
            # Usar sem√°foro para limitar transcri√ß√µes simult√¢neas
            # Isso evita sobrecarga do Whisper quando muitos chunks chegam ao mesmo tempo
            logger.debug(
                "üîÑ [TRANSCRI√á√ÉO] Aguardando slot dispon√≠vel para transcri√ß√£o",
                audio_length_sec=round(len(audio_array) / sample_rate, 2),
                active_transcriptions=self._active_transcriptions
            )
            
            # Adquirir sem√°foro ANTES de qualquer processamento
            # Isso garante que apenas uma transcri√ß√£o por vez seja processada
            async with self._transcription_semaphore:
                self._active_transcriptions += 1
                transcribe_start = time.perf_counter()
                result = None
                
                try:
                    # Verificar se modelo est√° carregado
                    if self.model is None:
                        logger.error("‚ùå [TRANSCRI√á√ÉO] Modelo faster-whisper n√£o est√° carregado!")
                        return {
                            'text': '',
                            'language': language or self.language,
                            'segments': [],
                            'confidence': 0.0
                        }
                    
                    logger.info(
                        "‚è≥ [TRANSCRI√á√ÉO] Chamando faster-whisper model.transcribe",
                        active_transcriptions=self._active_transcriptions,
                        audio_samples=len(audio_array),
                        audio_length_sec=round(len(audio_array) / sample_rate, 2),
                        model=self.model_name,
                        compute_type=self.compute_type,
                        timeout_sec=30.0
                    )
                    
                    # Criar fun√ß√£o de transcri√ß√£o para o executor
                    # faster-whisper retorna (segments, info) ao inv√©s de dict
                    model_ref = self.model
                    audio_ref = audio_array.copy()
                    options_ref = transcribe_options.copy()
                    language_ref = language or self.language  # Capturar language no closure
                    
                    def transcribe_sync():
                        try:
                            # faster-whisper retorna (segments, info)
                            # segments √© um iterador de objetos Segment
                            segments, info = model_ref.transcribe(audio_ref, **options_ref)
                            
                            # Converter segments para lista e processar
                            segments_list = list(segments)
                            
                            # Construir texto completo concatenando segmentos
                            text = " ".join(seg.text for seg in segments_list)
                            
                            # Converter segments para formato dict compat√≠vel
                            segments_dict = []
                            for seg in segments_list:
                                segments_dict.append({
                                    'start': seg.start,
                                    'end': seg.end,
                                    'text': seg.text,
                                    'no_speech_prob': getattr(seg, 'no_speech_prob', 0.0),
                                    'compression_ratio': getattr(seg, 'compression_ratio', 0.0),
                                    'avg_logprob': getattr(seg, 'avg_logprob', 0.0),
                                })
                            
                            # Retornar formato compat√≠vel com openai-whisper
                            return {
                                'text': text,
                                'language': info.language if hasattr(info, 'language') else language_ref,
                                'language_probability': getattr(info, 'language_probability', 1.0),
                                'segments': segments_dict,
                                'duration': getattr(info, 'duration', len(audio_ref) / sample_rate)
                            }
                        except Exception as e:
                            logger.error(f"Erro dentro do transcribe_sync: {e}")
                            raise
                    
                    # Adicionar timeout de 30 segundos
                    # faster-whisper √© mais r√°pido: tiny < 2s, base < 5s, small < 10s para 8s de √°udio
                    task = loop.run_in_executor(self._executor, transcribe_sync)
                    result = await asyncio.wait_for(task, timeout=30.0)
                    transcribe_latency_ms = (time.perf_counter() - transcribe_start) * 1000
                    
                    logger.info(
                        "‚úÖ [TRANSCRI√á√ÉO] faster-whisper retornou resultado",
                        latency_ms=round(transcribe_latency_ms, 2),
                        result_type=type(result).__name__,
                        has_text='text' in result if isinstance(result, dict) else False
                    )
                except asyncio.TimeoutError:
                    transcribe_latency_ms = (time.perf_counter() - transcribe_start) * 1000
                    logger.error(
                        "‚è±Ô∏è [TRANSCRI√á√ÉO] Timeout na transcri√ß√£o (30s excedido)",
                        latency_ms=round(transcribe_latency_ms, 2),
                        audio_length_sec=round(len(audio_array) / sample_rate, 2),
                        model=self.model_name
                    )
                    result = None
                except Exception as executor_error:
                    transcribe_latency_ms = (time.perf_counter() - transcribe_start) * 1000
                    logger.error(
                        "‚ùå [TRANSCRI√á√ÉO] Erro no executor do faster-whisper",
                        error=str(executor_error),
                        error_type=type(executor_error).__name__,
                        latency_ms=round(transcribe_latency_ms, 2)
                    )
                    result = None
                finally:
                    # Sempre decrementar contador, mesmo em caso de erro
                    self._active_transcriptions -= 1
                    logger.debug(
                        "üîì [TRANSCRI√á√ÉO] Sem√°foro liberado",
                        active_transcriptions=self._active_transcriptions
                    )
            
            # Verificar se result foi definido
            if result is None:
                return {
                    'text': '',
                    'language': language or self.language,
                    'segments': [],
                    'confidence': 0.0
                }
            
            # Extrair informa√ß√µes relevantes
            text = result.get('text', '').strip()
            detected_language = result.get('language', language or self.language)
            segments = result.get('segments', [])
            
            # Calcular confian√ßa m√©dia dos segmentos
            confidence = 0.0
            if segments:
                confidences = [
                    seg.get('no_speech_prob', 0.0) for seg in segments
                    if 'no_speech_prob' in seg
                ]
                if confidences:
                    # no_speech_prob √© a probabilidade de N√ÉO ter fala
                    # Queremos a probabilidade de TER fala, ent√£o: 1 - no_speech_prob
                    speech_probs = [1.0 - conf for conf in confidences]
                    confidence = float(np.mean(speech_probs)) if speech_probs else 0.0
            
            # Detectar repeti√ß√µes no texto (problema comum com √°udio ruim)
            text_words = text.split()
            unique_words = set(text_words)
            repetition_ratio = 1.0 - (len(unique_words) / len(text_words)) if text_words else 0.0
            has_repetition = repetition_ratio > 0.3  # Mais de 30% de repeti√ß√£o
            
            # Log detalhado dos segmentos para diagn√≥stico
            segment_previews = []
            if segments:
                for i, seg in enumerate(segments[:3]):  # Primeiros 3 segmentos
                    seg_text = seg.get('text', '').strip()
                    seg_no_speech = seg.get('no_speech_prob', 0.0)
                    segment_previews.append({
                        'index': i,
                        'text_preview': seg_text[:30] if seg_text else '',
                        'no_speech_prob': round(seg_no_speech, 2),
                        'start': round(seg.get('start', 0), 2),
                        'end': round(seg.get('end', 0), 2)
                    })
            
            logger.info(
                "‚úÖ [TRANSCRI√á√ÉO] Transcri√ß√£o conclu√≠da",
                text_length=len(text),
                text_preview=text[:100] if text else '',  # Aumentar preview para 100 chars
                text_full=text if len(text) <= 200 else text[:200] + '...',  # Texto completo se curto
                language=detected_language,
                confidence=round(confidence, 3),
                segments_count=len(segments),
                repetition_ratio=round(repetition_ratio, 2),
                has_repetition=has_repetition,
                segment_previews=segment_previews,
                latency_ms=round(transcribe_latency_ms, 2),
                warning="Repeti√ß√£o detectada" if has_repetition else None
            )
            
            return {
                'text': text,
                'language': detected_language,
                'segments': segments,
                'confidence': confidence
            }
            
        except Exception as e:
            logger.error(
                "Transcription failed",
                error=str(e),
                error_type=type(e).__name__
            )
            # Retornar resultado vazio em caso de erro
            return {
                'text': '',
                'language': language or self.language,
                'segments': [],
                'confidence': 0.0
            }
    
    def _decode_wav(self, wav_data: bytes, expected_sample_rate: int) -> Optional[np.ndarray]:
        """
        Decodifica dados WAV para array numpy.
        
        O formato WAV esperado:
        - Header de 44 bytes
        - Dados PCM16LE (16-bit little-endian)
        - Mono ou est√©reo
        
        Retorna:
        - Array numpy float32 normalizado (-1.0 a 1.0)
        - Taxa de amostragem ajustada se necess√°rio
        """
        try:
            import wave
            
            # Criar arquivo WAV em mem√≥ria
            wav_file = io.BytesIO(wav_data)
            
            # Ler WAV usando wave module
            with wave.open(wav_file, 'rb') as wf:
                sample_rate = wf.getframerate()
                num_channels = wf.getnchannels()
                sample_width = wf.getsampwidth()
                num_frames = wf.getnframes()
                
                # Ler dados de √°udio
                audio_bytes = wf.readframes(num_frames)
                
                # Converter bytes para array numpy
                if sample_width == 2:  # 16-bit
                    audio_array = np.frombuffer(audio_bytes, dtype=np.int16)
                elif sample_width == 4:  # 32-bit
                    audio_array = np.frombuffer(audio_bytes, dtype=np.int32)
                else:
                    logger.warn(f"Unsupported sample width: {sample_width}")
                    return None
                
                # Converter para float32 e normalizar (-1.0 a 1.0)
                # Para int16: dividir por 32768.0
                # Para int32: dividir por 2147483648.0
                if sample_width == 2:
                    audio_float = audio_array.astype(np.float32) / 32768.0
                else:
                    audio_float = audio_array.astype(np.float32) / 2147483648.0
                
                # Converter est√©reo para mono (m√©dia dos canais)
                if num_channels == 2:
                    audio_float = audio_float.reshape(-1, 2).mean(axis=1)
                
                # Resample se necess√°rio (Whisper funciona melhor com 16kHz)
                # Nota: Se o √°udio j√° estiver em 16kHz, n√£o precisa resample
                if sample_rate != expected_sample_rate:
                    try:
                        from scipy import signal
                        num_samples = int(len(audio_float) * expected_sample_rate / sample_rate)
                        if num_samples > 0:
                            audio_float = signal.resample(audio_float, num_samples)
                            logger.debug(
                                "Audio resampled",
                                from_rate=sample_rate,
                                to_rate=expected_sample_rate,
                                original_samples=len(audio_array),
                                resampled_samples=num_samples
                            )
                        else:
                            logger.warn("Invalid resample target, keeping original sample rate")
                    except ImportError:
                        logger.warn("scipy not available, skipping resample - Whisper will handle it")
                        # Whisper pode lidar com diferentes sample rates, mas 16kHz √© ideal
                    except Exception as e:
                        logger.warn(f"Resample failed: {e}, keeping original sample rate")
                else:
                    logger.debug("Audio already at target sample rate, no resample needed")
                
                return audio_float
                
        except Exception as e:
            logger.error("Failed to decode WAV", error=str(e))
            return None

